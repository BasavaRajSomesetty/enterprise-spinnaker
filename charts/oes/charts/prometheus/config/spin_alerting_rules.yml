groups:
- name: spinnaker-service-is-down
  rules:
  - alert: clouddriver-rw-is-down
    annotations:
      description: 'Service {{$labels.service}} in namespace {{$labels.namespace}}
        is not responding'
      summary: Clouddriver-rw Spinnaker service is down
    expr: absent(up{service="spin-clouddriver-rw"}) == 1
    labels:
      severity: critical
  - alert: clouddriver-ro-is-down
    annotations:
      description: 'Service {{$labels.service}} in namespace {{$labels.namespace}}
        is not responding'
      summary: Clouddriver-ro Spinnaker service is down
    expr: absent(up{service="spin-clouddriver-ro"}) == 1
    labels:
      severity: critical
  - alert: clouddriver-caching-is-down
    annotations:
      description: 'Service {{$labels.service}} in namespace {{$labels.namespace}}
        is not responding'
      summary: Clouddriver-caching Spinnaker service is down
    expr: absent(up{service="spin-clouddriver-caching"}) == 1
    labels:
      severity: critical
  - alert: gate-is-down
    annotations:
      description: 'Service {{$labels.service}} in namespace {{$labels.namespace}}
        is not responding'
      summary: Gate Spinnaker services is down
    expr: absent(up{service="spin-gate"}) == 1
    labels:
      severity: critical
  - alert: orca-is-down
    annotations:
      description: 'Service {{$labels.service}} in namespace {{$labels.namespace}}
        is not responding'
      summary: Orca Spinnaker service is down
    expr: absent(up{job="opsmx_spinnaker_metrics", service="spin-orca"}) == 1
    labels:
      severity: critical
  - alert: igor-is-down
    annotations:
      description: 'Service {{$labels.service}} in namespace {{$labels.namespace}}
        is not responding'
      summary: Igor Spinnaker service is down
    expr: absent(up{service="spin-igor"}) == 1
    labels:
      severity: critical
  - alert: echo-scheduler-is-down
    annotations:
      description: 'Service {{$labels.service}} in namespace {{$labels.namespace}}
        is not responding'
      summary: Echo-Scheduler Spinnaker service is down
    expr: absent(up{service="spin-echo-scheduler" }) == 1
    labels:
      severity: critical
  - alert: echo-worker-is-down
    annotations:
      description: 'Service {{$labels.service}} in namespace {{$labels.namespace}}
        is not responding'
      summary: Echo-worker Spinnaker service is down
    expr: absent(up{service="spin-echo-worker" }) == 1
    labels:
      severity: critical
  - alert: front50-is-down
    annotations:
      description: 'Service {{$labels.service}} in namespace {{$labels.namespace}}
        is not responding'
      summary: Front50 Spinnaker service is down
    expr: absent(up{service="spin-front50" }) == 1
    labels:
      severity: critical
- name: latency-too-high
  rules:
  - alert: clouddriver-ro-latency-too-high
    expr: sum(rate(clouddriver_ro:controller:invocations__count_total{service="spin-clouddriver-ro",statusCode="200"}[2m])) by (instance, method)/ sum(rate(clouddriver_ro:controller:invocations__total{service="spin-clouddriver-ro",statusCode="200"}[2m])) by (instance, method) > 70000
    for: 5m
    labels:
      severity: warning
    annotations:
      description: "Service {{$labels.service}} is slow ({{$value}} per minute)"
      summary: latency of clouddriver-ro is too high
  - alert: clouddriver-rw-latency-too-high
    expr: sum(rate(clouddriver_rw:controller:invocations__count_total{service="spin-clouddriver-rw",statusCode="200"}[2m])) by (instance, method)/ sum(rate(clouddriver_rw:controller:invocations__total{service="spin-clouddriver-rw",statusCode="200"}[2m])) by (instance, method) > 300
    for: 5m
    labels:
      severity: warning
    annotations:
      description: "Service {{$labels.service}} is slow ({{$value}} per minute)"
      summary: latency of clouddriver-rw is too high
  - alert: clouddriver-caching-latency-too-high
    expr: sum(rate(clouddriver_caching:controller:invocations__count_total{service="spin-clouddriver-caching",statusCode="200"}[2m])) by (instance, method)/ sum(rate(clouddriver_caching:controller:invocations__total{service="spin-clouddriver-caching",statusCode="200"}[2m])) by (instance, method) > 300
    for: 5m
    labels:
      severity: warning
    annotations:
      description: "Service {{$labels.service}} is slow ({{$value}} per minute)"
      summary: latency clouddriver-caching is too high
  - alert: gate-latency-too-high
    expr: sum(rate(gate:controller:invocations__count_total{service="spin-gate",statusCode="200"}[2m])) by (instance, method)/ sum(rate(gate:controller:invocations__total{service="spin-gate",statusCode="200"}[2m])) by (instance, method) > 5000
    for: 5m
    labels:
      severity: warning
    annotations:
      description: "Service {{$labels.service}} is slow ({{$value}} per minute)"
      summary: latency of gate is too high
  - alert: orca-latency-too-high
    expr: sum(rate(orca:controller:invocations__count_total{service="spin-orca",statusCode="200"}[2m])) by (instance, method)/ sum(rate(orca:controller:invocations__total{service="spin-orca",statusCode="200"}[2m])) by (instance, method) > 2000
    for: 5m
    labels:
      severity: warning
    annotations:
      description: "Service {{$labels.service}} is slow ({{$value}} per minute)"
      summary: latency of orca is too high
  - alert: igor-latency-too-high
    expr: sum(rate(igor:controller:invocations__count_total{service="spin-igor",statusCode="200"}[2m])) by (instance, method)/ sum(rate(igor:controller:invocations__total{service="spin-igor",statusCode="200"}[2m])) by (instance, method) > 10000
    for: 5m
    labels:
      severity: warning
    annotations:
      description: "Service {{$labels.service}} is slow ({{$value}} per minute)"
      summary: latency of igor is too high
  - alert: echo_scheduler-latency-too-high
    expr: sum(rate(echo_scheduler:controller:invocations__count_total{service="spin-echo-scheduler",statusCode="200"}[2m])) by (instance, method)/ sum(rate(echo_scheduler:controller:invocations__total{service="spin-echo-scheduler",statusCode="200"}[2m])) by (instance, method) > 6000
    for: 5m
    labels:
      severity: warning
    annotations:
      description: "Service {{$labels.service}} is slow ({{$value}} per minute)"
      summary: latency of echo-scheduler is too high
  - alert: echo_worker-latency-too-high
    expr: sum(rate(echo_worker:controller:invocations__count_total{service="spin-echo-worker",statusCode="200"}[2m])) by (instance, method)/ sum(rate(echo_worker:controller:invocations__total{service="spin-echo-worker",statusCode="200"}[2m])) by (instance, method) > 2000
    for: 5m
    labels:
      severity: warning
    annotations:
      description: "Service {{$labels.service}} is slow ({{$value}} per minute)"
      summary: latency of echo-worker is too high
  - alert: front50-latency-too-high
    expr: sum(rate(front50:controller:invocations__count_total{service="spin-front50",statusCode="200"}[2m])) by (instance, method)/ sum(rate(front50:controller:invocations__total{service="spin-front50",statusCode="200"}[2m])) by (instance, method) > 1200
    for: 5m
    labels:
      severity: warning
    annotations:
      description: "Service {{$labels.service}} is slow ({{$value}} per minute)"
      summary: latency of front50 is too high
- name: jvm-too-high
  rules:
  - alert: clouddriver-rw-pod-may-be-evicted-soon
    annotations:
      description: Service {{$labels.service}} in namespace {{$labels.namespace}}
        may be evicted soon
      summary: Clouddriver-rw JVM memory too high
    expr: (sum(clouddriver_rw:jvm:memory:used__value) by (instance, area) / sum(clouddriver_rw:jvm:memory:max__value) by (instance, area)) > .9
    labels:
      severity: warning
  - alert: clouddriver-ro-pod-may-be-evicted-soon
    annotations:
      description: Service {{$labels.service}} in namespace {{$labels.namespace}}
        may be evicted soon
      summary: Clouddriver-ro JVM memory too high
    expr: (sum(clouddriver_ro:jvm:memory:used__value) by (instance, area) / sum(clouddriver_ro:jvm:memory:max__value) by (instance, area)) > .9
    labels:
      severity: warning
  - alert: clouddriver-caching-pod-may-be-evicted-soon
    annotations:
      description: Service {{$labels.service}} in namespace {{$labels.namespace}}
        may be evicted soon
      summary: Clouddriver-caching JVM memory too high
    expr: (sum(clouddriver_caching:jvm:memory:used__value) by (instance, area) / sum(clouddriver_caching:jvm:memory:max__value) by (instance, area)) > .9
    labels:
      severity: warning
  - alert: gate-pod-may-be-evicted-soon
    annotations:
      description: Service {{$labels.service}} in namespace {{$labels.namespace}} may be evicted soon
      summary: gate JVM memory too high
    expr: (sum(gate:jvm:memory:used__value) by (instance, area) / sum(gate:jvm:memory:max__value) by (instance, area)) > .9
    labels:
      severity: warning
  - alert: orca-pod-may-be-evicted-soon
    annotations:
      description: Service {{$labels.service}} in namespace {{$labels.namespace}}
        may be evicted soon
      summary: orca JVM memory too high
    expr: (sum(orca:jvm:gc:liveDataSize__value) by (instance, area) / sum(orca:jvm:gc:maxDataSize__value) by (instance, area)) > .9
    labels:
      severity: warning
  - alert: igor-pod-may-be-evicted-soon
    annotations:
      description: Service {{$labels.service}} in namespace {{$labels.namespace}}
        may be evicted soon
      summary: igor JVM memory too high
    expr: (sum(igor:jvm:memory:used__value) by (instance, area) / sum(igor:jvm:memory:max__value) by (instance, area)) > .9
    labels:
      severity: warning
  - alert: echo-scheduler-pod-may-be-evicted-soon
    annotations:
      description: Service {{$labels.service}} in namespace {{$labels.namespace}}
        may be evicted soon
      summary: echo-scheduler JVM memory too high
    expr: (sum(echo_scheduler:jvm:memory:used__value) by (instance, area) / sum(echo_scheduler:jvm:memory:max__value) by (instance, area)) > .9
    labels:
      severity: warning
  - alert: echo-worker-pod-may-be-evicted-soon
    annotations:
      description: Service {{$labels.service}} in namespace {{$labels.namespace}}
        may be evicted soon
      summary: echo-worker JVM memory too high
    expr: (sum(echo_worker:jvm:memory:used__value) by (instance, area) / sum(echo_worker:jvm:memory:max__value) by (instance, area)) > .9
    labels:
      severity: warning
  - alert: front50-pod-may-be-evicted-soon
    annotations:
      description: Service {{$labels.service}} in namespace {{$labels.namespace}}
        may be evicted soon
      summary: Front50 JVM memory too high
    expr: (sum(front50:jvm:memory:used__value) by (instance, area) / sum(front50:jvm:memory:max__value) by (instance, area)) > .9
    labels:
      severity: warning
# Front50-Service specific alerts
- name: Front50-cache
  rules:
  - alert: "front50:storageServiceSupport:cacheAge__value"
    annotations:
      description: value = {{$value}}
      summary: "front50 cacheAge too high"
    expr: front50:storageServiceSupport:cacheAge__value > 300000
    for: 2m
    labels:
      severity: warning
# fiat-Service specific alerts
- name: Fiat-UserRoles-sync
  rules:
  - alert: fiat-userRoles-sync-time-too-high
    annotations:
      description: "Fiat userRoles sync time is high"
      summary: "fiat-userRoles-sync-time-too-high"
    expr: fiat:fiat:userRoles:syncTime__count_total/fiat:fiat:userRoles:syncTime__total > 8
    for: 2m
    labels:
      severity: warning            
- name: orca-queue-issue
  rules:
  - alert: orca-queue-depth-high
    annotations:
      description: Service {{$labels.service}} in namespace {{$labels.namespace}}
        may be evicted soon
      summary: Orca queue depth is high
    expr: (sum(orca:queue:ready:depth__value{namespace!=""}) by (instance)) > 10
    labels:
      severity: warning
  - alert: orca-queue-lag-high
    annotations:
      description: Lag = {{$value}}
      summary: Orca queue lag is high
    expr: sum(rate (orca:controller:invocations__total[2m])) by (instance)  / sum(rate(orca:controller:invocations__count_total[2m])) by (instance) > 0.5
    labels:
      severity: warning
- name: igor-needs-attention
  rules:
  - alert: igor-needs-attention
    annotations:
      description: Igor in namespace {{$labels.namespace}} needs human help
      summary: Igor needs attention
    expr: igor:pollingMonitor:itemsOverThreshold__value > 0
    labels:
      severity: crtical
- name: echo-scheduler-okhttp
  rules:
  - alert: echo-schedulerok-http
    annotations:
      description: echo needs attention
      summary: echo needs attention
    expr: sum(rate(echo_scheduler:okhttp:requests__count_total{service="spin-echo-scheduler",statusCode="200"}[2m])) by (instance, method) /
      sum(rate(echo_scheduler:okhttp:requests__total{service="spin-echo-scheduler",statusCode="200"}[2m])) by (instance, method) > 100
    for: 1m
    labels:
      severity: warning
- name: echo-worker-okhttp
  rules:
  - alert: echo-workerok-http
    annotations:
      description: echo needs attention
      summary: echo needs attention
    expr: sum(rate(echo_worker:okhttp:requests__count_total{service="spin-echo-worker",statusCode="200"}[2m])) by (instance, method) /
      sum(rate(echo_worker:okhttp:requests__total{service="spin-echo-worker",statusCode="200"}[2m])) by (instance, method) > 100
    for: 1m
    labels:
      severity: warning
- name: clouddriver-ro-okhttp
  rules:
  - alert: clouddriver-ro-http
    annotations:
      description: clouddriver-ro needs attention
      summary: clouddriver-ro needs attention
    expr: sum(rate(clouddriver_ro:okhttp:requests__count_total{service="spin-clouddriver-ro",statusCode="200"}[2m])) by (instance, method) /
      sum(rate(clouddriver_ro:okhttp:requests__total{service="spin-clouddriver-ro",statusCode="200"}[2m])) by (instance, method) > 300
    for: 1m
    labels:
      severity: warning
- name: clouddriver-rw-okhttp
  rules:
  - alert: clouddriver-rw-http
    annotations:
      description: clouddriver-rw needs attention
      summary: clouddriver-rw needs attention
    expr: sum(rate(clouddriver_rw:okhttp:requests__count_total{service="spin-clouddriver-rw",statusCode="200"}[2m])) by (instance, method) /
      sum(rate(clouddriver_rw:okhttp:requests__total{service="spin-clouddriver-rw",statusCode="200"}[2m])) by (instance, method) > 100
    for: 1m
    labels:
      severity: warning
- name: fiat-okhttp
  rules:
  - alert: fiat-okhttp
    annotations:
      description: fiat needs attention
      summary: fiat needs attention
    expr: sum(rate(fiat:okhttp:requests__count_total{service="spin-fiat",statusCode="200"}[2m])) by (instance, method) /
      sum(rate(fiat:okhttp:requests__total{service="spin-fiat",statusCode="200"}[2m])) by (instance, method) > 300
    for: 1m
    labels:
      severity: warning
- name: gate-okhttp
  rules:
  - alert: gate-okhttp
    annotations:
      description: gate needs attention
      summary: gate needs attention
    expr: sum(rate(gate:okhttp:requests__count_total{service="spin-gate",statusCode="200"}[2m])) by (instance, method) /
      sum(rate(gate:okhttp:requests__total{service="spin-gate",statusCode="200"}[2m])) by (instance, method) > 50
    for: 1m
    labels:
      severity: warning
- name: igor-okhttp
  rules:
  - alert: igor-okhttp
    annotations:
      description: igor needs attention
      summary: igor needs attention
    expr: sum(rate(igor:okhttp:requests__count_total{service="spin-igor",statusCode="200"}[2m])) by (instance, method) /
      sum(rate(igor:okhttp:requests__total{service="spin-igor",statusCode="200"}[2m])) by (instance, method) > 40
    for: 1m
    labels:
      severity: warning
- name: orca-okhttp
  rules:
  - alert: orca-okhttp
    annotations:
      description: orca needs attention
      summary: orca needs attention
    expr: sum(rate(orca:okhttp:requests__count_total{service="spin-orca",statusCode="200"}[2m])) by (instance, method) /
      sum(rate(orca:okhttp:requests__total{service="spin-orca",statusCode="200"}[2m])) by (instance, method) > 300
    for: 1m
    labels:
      severity: warning
- name: rosco-okhttp
  rules:
  - alert: rosco-okhttp
    annotations:
      description: roscoin needs attention
      summary: rosco needs attention
    expr: sum(rate(front50:okhttp:requests__count_total{service="spin-front50",statusCode="200"}[2m])) by (instance, method)/
      sum(rate(front50:okhttp:requests__total{service="spin-front50",statusCode="200"}[2m])) by (instance, method) > 300
    for: 1m
    labels:
      severity: warning      
- name: autopilot-scrape-target-is-down
  rules:
  - alert: oes-audit-client-scrape-target-is-down
    annotations:
      description: The scrape target endpoint of component {{$labels.component}} in namespace {{$labels.kubernetes_namespace}} is down
      summary: oes-audit-client scrape target is down
    expr: up{component="auditclient"}==0
    labels:
      severity: critical
  - alert: oes-autopilot-scrape-target-is-down
    annotations:
      description: The scrape target endpoint of component {{$labels.component}} in namespace {{$labels.kubernetes_namespace}} is down
      summary: oes-autopilot scrape target is down
    expr: up{component="autopilot"}==0
    labels:
      severity: critical
  - alert: oes-dashboard-scrape-target-is-down
    annotations:
      description:  The scrape target endpoint of component {{$labels.component}} in namespace {{$labels.kubernetes_namespace}} is down
      summary: oes-dashboard scrape target is down
    expr: up{component="dashboard"}==0
    labels:
      severity: critical		  
  - alert: oes-platform-scrape-target-is-down
    annotations:
      description: The scrape target endpoint of component {{$labels.component}} in namespace {{$labels.kubernetes_namespace}} is down
      summary: oes-platform scrape target is down
    expr: up{component="platform"}==0
    labels:
      severity: critical
  - alert: oes-sapor-scrape-target-is-down
    annotations:
      description: The scrape target endpoint of component {{$labels.component}} in namespace {{$labels.kubernetes_namespace}} is down
      summary: oes-sapor scrape target is down
    expr: up{component="sapor"}==0
    labels:
      severity: critical		  
  - alert: oes-visibility-scrape-target-is-down
    annotations:
      description: The scrape target endpoint of component {{$labels.component}} in namespace {{$labels.kubernetes_namespace}} is down
      summary: oes-visibility scrape target is down
    expr: up{component="visibility"}==0
    labels:
      severity: critical
- name: Default Prometheus Job is Down 
  rules:
  - alert: PROMETHEUS_JOB_IS_DOWN
    expr: up{job="prometheus"} == 0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: The Default Prometheus Job is Down (job {{ $labels.job}})
      description: "Default Prometheus Job is Down LABELS = {{ $labels }}" 
- name: Volume is almost full (< 10% left)
  rules:
  - alert: PVC_STORAGE_FULL
    expr: kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100 < 10
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: Kubernetes Volume running out of disk space for (persistentvolumeclaim {{ $labels.persistentvolumeclaim }} in namespace {{$labels.namespace}})
      description: "Volume is almost full (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
- name: Kubernetes API server is experiencing high error rate
  rules:
  - alert: KUBE_API_SERVER_ERRORS
    expr: sum(rate(apiserver_request_total{job="kubernetes-apiservers",code=~"^(?:5..)$"}[2m])) / sum(rate(apiserver_request_total{job="kubernetes-apiservers"}[2m])) * 100 > 3
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: Kubernetes API server errors (instance {{ $labels.instance }})
      description: "Kubernetes API server is experiencing high error rate\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
- name: Latency too high
  rules:
  - alert: TOO_HIGH_LATENCY
    expr: sum(rate(http_server_requests_seconds_sum{component!=""}[2m])) by (kubernetes_pod_name, method, outcome, status, component, kubernetes_namespace)/sum(rate(http_server_requests_seconds_count{component!=""}[2m])) by (kubernetes_pod_name, method, outcome, status, component, kubernetes_namespace) > 0.1
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: Latency of the component (component {{ $labels.component }} in namespace {{$labels.kubernetes_namespace}} is high)
      description: "Latency of the component\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
- name: Kube-API Server is down
  rules:
  - alert: KUBE_API_SERVER_DOWN
    expr: up{job="kubernetes-apiservers"} == 0
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: Kube API Server job {{ $labels.job }} is down
      description: "Kubernetes API Server service went down LABELS = {{ $labels }}" 
- name: JVM_Errors
  rules:
  - alert: JVM_Memory_Filling_Up
    expr: (sum by (instance)(jvm_memory_used_bytes{area="heap"}) / sum by (instance)(jvm_memory_max_bytes{area="heap"})) * 100 > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: JVM memory filling up (instance {{ $labels.instance }} for pod {{ $labels.kubernetes_pod_name }} in namespace {{ $labels.kubernetes_namespace }})
      description: "JVM memory is filling up for {{ $labels.kubernetes_pod_name }} in namespace {{ $labels.kubernetes_namespace }} (> 80%)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
  - alert: JVM_Reaching_Peak_Thread_Count
    expr: (sum by (instance, kubernetes_pod_name, kubernetes_namespace)(jvm_threads_live_threads/jvm_threads_peak_threads)) * 100 > 95
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: JVM live thread count is reaching its previous peak thread count since the JVM started/peak was reset 
      description: "JVM live thread count for pod {{ $labels.kubernetes_pod_name }} in namespace {{ $labels.kubernetes_namespace }} is reaching its previous max peak thread count"