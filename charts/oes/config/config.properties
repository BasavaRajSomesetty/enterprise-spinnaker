kubernetes.prometheus.metric.label=__name__
    kubernetes.prometheus.host.tagname=exported_container_label_io_kubernetes_pod_name
    kubernetes.prometheus.tomcat.host.tagname=container_label_io_kubernetes_pod_name
    aws.prometheus.host.tagname=instance
    aws.prometheus.baseline.host.tagvalue=version2a
    aws.prometheus.canary.host.tagvalue=version2b


    prometheus.metrics.api.path=/api/v1/label/__name__/values
    prometheus.metrics.aggregator=avg
    prometheus.metrics.sampling.value=10
    prometheus.metrics.rate.duration=60s
    #true always taking cluster name, false always taking pod names
    prometheus.cluster.name=false
    isPodFinderEnabled=false
    
    management.endpoints.web.base-path=/mgmt
    management.endpoint.health.show-details=always
    management.endpoint.health.show-components=always

    prometheus.services=apache,haproxy,http,tomcat
    prometheus.configured.service=istio
    stackdriver.services=tomcat
    stackdriver.metrics.template.path=/opt/opsmx/base-templates/stackdriver/tomcat-metrics.json
    elastic.search.services=apache,tomcat
    #datadog.services=tomcat (datadog services are being read from datadog api by truncating the prefix of each metric name
    #custom.service.dropdown.value=Custom service

    #Reading hibernate.cfg.xml from file system
    hibernate.configFilePath=/opt/opsmx/hibernate.cfg.xml

    #Data science micro service configuration parameters
    python.server.protocol=http://
    python.analysis.url=localhost:5005

    #Data Science Microservice Properties
    datascience.workers.count=4
    datascience.server.address=0.0.0.0:5005

    #aws.prometheus.hostname=
    server.protocol=http://
    reporting.server.url=/opsmx-analysis/public/canaryAnalysis.html#/analysis/
    casservice.baseurl=localhost:8090
    metricservice.baseurl=localhost:9090

    elastic.search.metrics.template.path=/opt/opsmx/elasticsearch_template_format.json
    elasticsearch.metrics.sampling.value=10
    elastic.search.query.template.path=/opt/opsmx/elasticsearch_metric_query_template.json
    elastic.search.metrics.index.path=/opt/opsmx/elasticsearch_index_template.json
    elastic.search.kibana.url=http://localhost:5601/app/kibana#/discover?_g=()&_a=(columns:!(_source),index:METRIC_INDEX,interval:auto,query:(language:lucene,query:''),sort:!('@timestamp',desc))

    #Required details for log analysis
    home.directory=/home/ubuntu/
    logfiles.base.path=/home/ubuntu/logdata/
    logfiles.aca.path=/home/ubuntu/acainputs/
    logfiles.feedback.path=/home/ubuntu/logdata/feedback/
    logfiles.pca.path=/home/ubuntu/ScoringAndPCA/
    java.logs.path=/home/ubuntu/logs/
    k8.logpulling.url=
    k8.logpulling.username=admin
    k8.logpulling.password=
    k8.query.keyword=kubernetes.pod_name.keyword
    k8.config.filepath=/home/ubuntu/.kube/
    elasticsearch.k8.log.query.file.path=/opt/opsmx/base-templates/elasticsearch/elasticsearch_log_query.json
    elasticsearch.log.query.file.path=/opt/opsmx/base-templates/elasticsearch/elasticsearch_log_query.json
    elasticsearch.logpulling.url=/_search?scroll=2m
    dockerswarm.logpulling.scroll.url=/_search/scroll
    dockerswarm.query.file.path=/opt/opsmx/base-templates/elasticsearch/elasticsearch_swarmlog_query.json
    elasticsearch.query.keyword=container_id.keyword
    elasticsearch.response.keywords=message,exception.exception_message,log
    elasticsearch.log.filesize.in.MB=100

    #sumologic detials
    sumologic.logpulling.url1=https://api.
    sumologic.logpulling.url2=.sumologic.com/api/v1/search/jobs
    sumologic.logpulling.us1=https://api.sumologic.com/api/v1/search/jobs
    sumologic.log.query.file.path=/opt/opsmx/base-templates/sumologic/sumologic_log_query.json
    sumologic.response.keywords=message,exception.exception_message,log
    sumologic.log.filesize.in.MB=100
    sumologic.accessid.keyword=dummyaccessid
    sumologic.accesskey.keyword=dummyaccesskey
    sumologic.zone.keyword=us2
    sumologic.query.keyword=container_id.keyword
    sumologic.query.url=https://service.<zone>.sumologic.com/ui/#/search/@<starttime>,<endtime>@_sourceCategory=<pod>
    sumologic.query.url.us1=https://service.sumologic.com/ui/#/search/@<starttime>,<endtime>@_sourceCategory=<pod>
    sumologic.query.data=/messages?offset=0&limit=10000

    #stackdriver details
    stackdriver.services=tomcat
    stackdriver.metrics.template.path=/opt/opsmx/base-templates/stackdriver/apm.json
    stackdriver.query.url=https://console.cloud.google.com/logs/#/search/@<logfilter>

    #Kibana details
    kibana.query.url=/app/kibana#/discover?_g=(refreshInterval:(pause:!t,value:0),time:(from:'<starttime>',mode:absolute,to:'<endtime>'))&_a=(columns:!(_source),filters:!(('$state':(store:appState),meta:(alias:!n,disabled:!f,index:<index>,key:_index,negate:!f,params:(query:'<indexvalue>',type:phrase),type:phrase,value:'<indexvalue>'),query:(match:(_index:(query:'<indexvalue>',type:phrase)))),('$state':(store:appState),meta:(alias:!n,disabled:!f,index:<index>,key:<scope>,negate:!f,params:!('<scopevalue>'),type:phrases,value:'<scopevalue>'),query:(bool:(minimum_should_match:1,should:!((match_phrase:(<scope>:'<scopevalue>'))))))),index:<index>,interval:auto,query:(language:lucene,query:''),sort:!('@timestamp',desc))

    kibana.query=/app/kibana#/discover?_g=()&_a=(columns:!(_source),index:<index>,interval:auto,query:(language:lucene,query:''),sort:!('@timestamp',desc))

    elasticsearch.index=logstash-pipeline-*
    log.template=log-template
    metric.template=metric-template
    log.analysis.file=/home/ubuntu/logdata/logAnalysis.py
    canary.analysis.filepath=/home/ubuntu/Python-code/canary/canaryplusversion.py
    log.feedback.analysis.file=/home/ubuntu/logdata/feedbackAnalysis.py
    python.version=python

    #Retry the log query attributes
    totalDurationInMinutes=1
    intervalDurationInSeconds=10

    newrelic.metric.template.filter.params=WebTransaction(.*)GET(.*),WebTransaction(.+)POST(.*),WebTransaction(.+)PUT(.*),WebTransaction(.+)DELETE(.*),WebTransaction(.+)PATCH(.*)
    newrelic.metrics.template.path=/opt/opsmx/base-templates/newrelic/newrelic-apm-rest.json
    #newrelic.metric.template.filter.param=/greeting
    newrelic.group.metric.delimiter=;

    #datadog metric analysis required details
    datadog.metric.tag=host
    datadog.metrics.template.path=/opt/opsmx/base-templates/datadog/
    datadog.infra.metrics.template.path=/opt/opsmx/base-templates/datadog/infra.json
    datadog.timeseries.metricdata.client.url=https://api.datadoghq.com/api/v1/query
    datadog.apm.metrics.template.path=/opt/opsmx/base-templates/datadog/apm.json
    datadog.timeseries.metricdata.host=api.datadoghq.com
    datadog.application.weeks=1

    canary.default.minscore=80
    canary.default.maxscore=90
    metricdata.fetcher.url=http://localhost:8090/metricdata
    monitoring.service.baseurl=http://localhost:8090

    basedata.filepath=/home/ubuntu/BaseData/USER_NAME_PLACE_HOLDER/TEMPLATE_NAME_PLACE_HOLDER/Data
    #time period is in hours
    basedata.time.period=-24
    system.r.path=/usr/bin/Rscript
    weights.computation.filepath=/home/ubuntu/long_term_weights.R

    sonar.metrics.file.path=/opt/opsmx/base-templates/sonar/sonar_metrics.json

    auditEnabled=false
    python.algorithm=spell
    spinnaker.login.admin.enabled=false
    spinnaker.baseurl=http://spin-gate:8084
    spinnaker.login.admin.username=TestUser
    spinnaker.login.admin.password=TestPassword

    #ldap login attributes
    isLdapAuthEnabled=false
    ldap.url=ldap://oes-openldap:389
    ldap.base.dn=cn=Users,dc=local,dc=opsmx,dc=com
    ldap.user.filter.pattern=(&(cn=USERNAME))
    ldap.user.filter.pattern=(&(objectclass=person)(cn=USERNAME))
    ldap.admin.user.groups=Administrators

    #SSL certificate details
    # server.ssl.key-store: keystore.p12
    # server.ssl.key-store-password: OpsMx@123
    # server.ssl.keyStoreType: PKCS12
    # server.ssl.keyAlias: tomcat

    #JDBC for Audit Service
    spring.datasource.url=jdbc:postgresql://db-opsmx:5432/opsmx
    spring.datasource.username=postgres
    spring.datasource.password=networks123

    # timing parameters for analysis retries.
    opsmx.job.refreshMilliseconds=30000
    opsmx.job.timeoutMilliseconds=120000
    opsmx.job.restartJobLimit=5
    opxmx.job.staleCheckMilliseconds=60000

    #Thread limit for calls to analysis servicec
    analysis.threadpool.size=4
    
    #Enable Build Analysis
    build.analysis=false

    # metric multi service constants
    multiservice.monitoring.service.url=localhost:9090/metricdatapath
